{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c27c652",
   "metadata": {},
   "source": [
    "## Step 0: Importing the Appropriate Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ab893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import astropy\n",
    "import emcee\n",
    "import corner\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import astropy.constants as ac\n",
    "from astropy import units as u\n",
    "from astropy.convolution import Gaussian1DKernel, convolve\n",
    "from astropy.modeling import models\n",
    "from astropy.visualization import quantity_support\n",
    "from scipy.optimize import minimize\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000bcfe4",
   "metadata": {},
   "source": [
    "## Step 1: Importing Data and Changing the Units of the Variables\n",
    "\n",
    "We'll first import and read the following data:\n",
    "\n",
    "1. chen+07_slshlh.dat; This contains the Spitzer IRS spectrum of BetaPic from ~5-35 microns. \n",
    "\n",
    "2. betapic_fluxes.dat; This contains assorted photometry from the optical and infrared with BetaPic. \n",
    "\n",
    "3. betapic_lws_cnt3_.txt; This contains the ISO LWS spectrum of BetaPic, from ~43 to 160 microns.\n",
    "\n",
    "### 1.1: Using the correct folders to pull the data from and to put the data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41c81860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first the main directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# then the appropriate folders inside this main directory\n",
    "Photom_IRS = cwd + \"\\\\data\\\\betapic_data\\DiskModels\\Debris\\BetaPic\" # where the photometry and IRS Spectrum is found\n",
    "LWS = cwd + \"\\\\data\\\\betapic_data\\DiskModels\\Debris\\BetaPic\\iso\\hpdp_62003530_3\" # where the LWS Spectrum is found\n",
    "\n",
    "Ice = cwd + \"\\\\data\\\\water_ice_opacities_lsbrp\" # where the different opacity files are found\n",
    "Silicates = cwd + \"\\\\data\\\\silicates_for_betapic\" # where the different silicate files are found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e553c8",
   "metadata": {},
   "source": [
    "### 1.2: Importing the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae4dae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the photometry and IRS Spectrum files\n",
    "os.chdir(Photom_IRS)\n",
    "\n",
    "# Columns are all labelled (wavelength in microns, flux (F_nu) and uncertainty in Janskys, (Jy)).\n",
    "Spitzer_IRS = np.loadtxt('chen+07_slshlh.dat')\n",
    "Wavelength_IRS, Flux_IRS_Jy, Error_IRS_Jy = Spitzer_IRS[:,0], Spitzer_IRS[:,1], Spitzer_IRS[:,2]\n",
    "\n",
    "# Columns are formatted as wavelength (mircons), flux (F_nu, Jy), uncertainty (Jy).\n",
    "Photom = np.loadtxt('betapic_fluxes.dat')\n",
    "Wavelength_Photom, Flux_Photom_Jy, Error_Photom_Jy = Photom[:,0], Photom[:,1], Photom[:,2]\n",
    "\n",
    "\n",
    "# Changing directory to the LWS Spectrum file\n",
    "os.chdir(LWS)\n",
    "\n",
    "# Columns are formatted  as wavelength (microns), nu*F_nu (erg/cm^2/s), and uncertainty in nu*F_nu (same units).\n",
    "ISO_LWS = np.loadtxt('betapic_lws_cnt3_.txt')\n",
    "Wavelength_LWS, Flux_LWS, Error_LWS = ISO_LWS[:,0], ISO_LWS[:,1], ISO_LWS[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48969122",
   "metadata": {},
   "source": [
    "### 1.3: Rewriting the units\n",
    "We need to convert the fluxes and error from Jansky to erg cm$^{-2}$ s$^{-1}$ . We know that 1 Jy equals to 10$^{23}$ erg cm$^{-2}$ s$^{-1}$ Hz$^{-1}$.\n",
    "\n",
    "Such that we get: erg cm$^{-2}$ s$^{-1}$ = 10$^{-23}$ Hz Jy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea58e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now calculate the flux using F = v*F_v (also making sure that the wavelength is in meters and not in microns)\n",
    "Flux_IRS = 10**(-23)*Flux_IRS_Jy*(ac.c.value/(Wavelength_IRS*10**(-6)))\n",
    "Flux_Photom = 10**(-23)*Flux_Photom_Jy*(ac.c.value/(Wavelength_Photom*10**(-6)))\n",
    "\n",
    "# We can now also calculate the error in the fluxes\n",
    "Error_IRS = 10**(-23)*Error_IRS_Jy*(ac.c.value/(Wavelength_IRS*10**(-6)))\n",
    "Error_Photom = 10**(-23)*Error_Photom_Jy*(ac.c.value/(Wavelength_Photom*10**(-6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd5a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure no flux is zero/negative\n",
    "Flux_IRS, Wavelength_IRS, Error_IRS = Flux_IRS[Flux_IRS>0], Wavelength_IRS[Flux_IRS>0], Error_IRS[Flux_IRS>0]\n",
    "Flux_Photom, Wavelength_Photom, Error_Photom = Flux_Photom[Flux_Photom>0], Wavelength_Photom[Flux_Photom>0], Error_Photom[Flux_Photom>0]\n",
    "\n",
    "# Removing the negative values\n",
    "Flux_LWS, Wavelength_LWS, Error_LWS = Flux_LWS[Flux_LWS>0], Wavelength_LWS[Flux_LWS>0], Error_LWS[Flux_LWS>0]\n",
    "\n",
    "# Removing the error equal to 0 from the photometry\n",
    "Error_Photom, Flux_Photom, Wavelength_Photom = Error_Photom[Error_Photom!=0], Flux_Photom[Error_Photom!=0], Wavelength_Photom[Error_Photom!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31252f9a",
   "metadata": {},
   "source": [
    "We need to convolve LWS Spectrum to smoothen it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "203860ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create kernel & convolving lWS spectrum\n",
    "g = Gaussian1DKernel(stddev=3)\n",
    "z = convolve(Flux_LWS, g)\n",
    "\n",
    "# Removing the tail of the LWS spectrum [by trial and error]\n",
    "Wavelength_z, z, Error_z = Wavelength_LWS[6:], z[6:], Error_LWS[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7301d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list with all ice opacity file names\n",
    "os.chdir(Ice)\n",
    "ice = sorted(glob.glob(\"h2oice.p3p5.amin0p005.amax*.wb08c146\"))\n",
    "\n",
    "# Columns have the format: wavelength (microns), total opacity, albedo, absorption coefficient, asymmetry parameter g\n",
    "# Read the files in with np.loadtxt('filename')\n",
    "\n",
    "# Creating a list with all silicate opacity file names\n",
    "os.chdir(Silicates)\n",
    "silicates = sorted(glob.glob(\"sil.p3p5.amax*.extinc\"))\n",
    "\n",
    "# Returning to main directory\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedcc39",
   "metadata": {},
   "source": [
    "## Chi Squared Fit\n",
    "\n",
    "### Reading in the Ice and Silicate Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3ec8866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tau(kappa, mass, d):\n",
    "    return kappa*(mass*(ac.M_earth).value*10**(3))/(d**2)\n",
    "\n",
    "def chi_sq(model, flux, error):\n",
    "    \"\"\"Calculates the chi squared value.\"\"\"\n",
    "    return np.sum(((model-flux)/error)**2)\n",
    "\n",
    "def spectrum_ice_si(wave, x_b, x_d,  kappa_ice, kappa_si, d):\n",
    "    \"\"\"Creates a model for the flux of a star, for which a blackbody approximation is used,\n",
    "    in combination with a ring for which both ice and silicates opacities are\n",
    "    taken into account.\"\"\"\n",
    "    T, SolidAngle = x_b\n",
    "    T_2, mass_i, mass_s = x_d\n",
    "    \n",
    "    bb = models.BlackBody(temperature=T*u.K)\n",
    "    B_q_1 = bb(wave*u.micron)\n",
    "    bb_2 = models.BlackBody(temperature=T_2*u.K)\n",
    "    B_q_2 = bb_2(wave*u.micron)\n",
    "    \n",
    "    t_ice = tau(kappa_ice, mass_i, d)/0.0005\n",
    "    t_si = tau(kappa_si, mass_s, d)/0.004\n",
    "        \n",
    "    F_1 = (SolidAngle)*B_q_1*(ac.c/(wave*u.micron))\n",
    "    F_2 = B_q_2*(ac.c/(wave*u.micron))\n",
    "    \n",
    "    F = F_1 + (t_ice + t_si)*F_2\n",
    "    return F.to(u.erg * u.cm**(-2) * u.s**(-1) * u.sr**(-1)).value\n",
    "\n",
    "def chi_squared_ice_si(x0, wave, x0_beta, flux_ISO, error_ISO, d, kappa_ice, kappa_si):\n",
    "    \"\"\"Calculates the reduced chi^2 value for a given set of parameters and data points\n",
    "    (with the corresponding errors) for a certain model. This definition is for the \n",
    "    the determination of the reduced chi^2 value of the flux of a model.\"\"\"\n",
    "    for i in x0:\n",
    "        if i < 0:\n",
    "            return np.inf\n",
    "    \n",
    "    model = spectrum_ice_si(wave, x0_beta, x0, kappa_ice, kappa_si, d)\n",
    "    chi = chi_sq(model, flux_ISO, error_ISO)\n",
    "    return chi/(len(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5bb73f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index ice: 2  -  h2oice.p3p5.amin0p005.amax15.g.ab0p0005.wb08c146\n",
      "index silicates: 5  -  sil.p3p5.amax1mm.g.ab0p004.extinc\n",
      "chi^2: 0.09119760765264488\n",
      "[T_1, M_I, M_S1]: [7.83099651e+01 1.96042592e-04 1.34327379e-02]\n"
     ]
    }
   ],
   "source": [
    "phi = [80, 1e-5, 1e-2] # phi is [dust temperature, mass ice, mass silicates]\n",
    "\n",
    "fit_mask = ( (Wavelength_z<=100) )\n",
    "\n",
    "d_BetaPic = (19.76*u.pc).to(u.cm).value\n",
    "x0_BetaPic = [8200, 1.2699*10**(-17)]\n",
    "\n",
    "estimates_LWS=[]\n",
    "chi_LWS = []\n",
    "array_chi_LWS_ = np.array([[0,0,0,0,0,0]])\n",
    "\n",
    "silicates_best = []\n",
    "estimates_j = []\n",
    "\n",
    "for i in range(len(ice)): # Creating a for loop to loop over all ice opacity files\n",
    "    chi_j = []\n",
    "    \n",
    "    os.chdir(Ice)\n",
    "    Ice_i = np.loadtxt(ice[i],skiprows=1)\n",
    "    \n",
    "    f_i = interpolate.interp1d(Ice_i[:,0], Ice_i[:,1]) #Interpolating to make the array's match \n",
    "    kappa_ice_new = f_i(Wavelength_z[fit_mask])\n",
    "\n",
    "    for j in range(len(silicates)): # Creating a for loop to loop over all silicate files\n",
    "        os.chdir(Silicates)\n",
    "        silicate_j = np.loadtxt(silicates[j],skiprows=1)\n",
    "        \n",
    "        f_si = interpolate.interp1d(silicate_j[:,0], silicate_j[:,1]) #Interpolating to make the array's match \n",
    "        kappa_si_new = f_si(Wavelength_z[fit_mask])\n",
    "        \n",
    "        estimates_i = minimize(fun=chi_squared_ice_si, x0 = phi, args=(Wavelength_z[fit_mask], x0_BetaPic, \n",
    "                                                                   z[fit_mask], Error_z[fit_mask], \n",
    "                                                                   d_BetaPic, kappa_ice_new, kappa_si_new), \n",
    "                           method = 'Nelder-Mead')\n",
    "\n",
    "        chi_j.append(estimates_i.fun)\n",
    "        estimates_j.append(estimates_i.x)\n",
    "        \n",
    "        # Such that we can see all possible combinations with their final chi-value (+variables)\n",
    "        array_chi_LWS_ = np.append(array_chi_LWS_, [[ice[i], silicates[j], estimates_i.fun, estimates_i.x[0],\n",
    "                                                   estimates_i.x[1], estimates_i.x[2]]], axis = 0)\n",
    "\n",
    "        \n",
    "    j_best = np.where(chi_j==np.min(chi_j))[0][0] # Finding which silicate file is best for the i'th ice opacity file\n",
    "    silicates_best.append(j_best)\n",
    "    \n",
    "    chi_LWS.append(chi_j[j_best])\n",
    "    estimates_LWS.append(estimates_j[j_best])\n",
    "\n",
    "best_i_LWS = np.where(chi_LWS==np.min(chi_LWS))[0][0] # Finding which ice file is best for the fit\n",
    "\n",
    "print('index ice:', best_i_LWS, \" - \", ice[best_i_LWS])\n",
    "print('index silicates:', silicates_best[best_i_LWS], \" - \", silicates[silicates_best[best_i_LWS]])\n",
    "print('chi^2:', chi_LWS[best_i_LWS])\n",
    "print('[T_1, M_I, M_S1]:', estimates_LWS[best_i_LWS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40125966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
